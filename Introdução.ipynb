{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introdução**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste e previsão: fundamentos do estimador<br>\n",
    "O Scikit-learn fornece dezenas de algoritmos e modelos de aprendizado de máquina integrados, chamados estimadores . Cada estimador pode ser ajustado a alguns dados usando seu método de ajuste .\n",
    "\n",
    "Abaixo está um exemplo simples onde ajustamos um ***RandomForestClassifiera*** a alguns dados muito básicos.\n",
    "\n",
    "Uma floresta aleatória é um meta estimador que ajusta vários classificadores de árvore de decisão em várias subamostras do conjunto de dados e usa a média para melhorar a precisão preditiva e controlar o ajuste excessivo. O tamanho da subamostra é controlado com o max_samplesparâmetro if bootstrap=True(padrão), caso contrário, todo o conjunto de dados é usado para construir cada árvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "X = [[ 1,  2,  3],  # 2 amostras, 3 features\n",
    "     [11, 12, 13]]\n",
    "y = [0, 1]          # classes de cada amostra\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método de ajuste geralmente aceita 2 entradas:\n",
    "\n",
    "* A matriz de amostras (ou matriz de projeto) X . O tamanho de X normalmente é , o que significa que as amostras são representadas como linhas e os recursos são representados como colunas.(n_samples, n_features)\n",
    "\n",
    "* Os valores alvo y que são números reais para tarefas de regressão ou inteiros para classificação (ou qualquer outro conjunto discreto de valores). Para tarefas de aprendizado não supervisionadas, ynão precisa ser especificado. yé geralmente 1d array onde a iª entrada corresponde ao destino da iª amostra (linha) de X.\n",
    "\n",
    "Ambos Xe ygeralmente são matrizes numpy ou tipos de dados semelhantes a matrizes equivalentes , embora alguns estimadores trabalhem com outros formatos, como matrizes esparsas.\n",
    "\n",
    "Uma vez que o estimador esteja ajustado, ele pode ser usado para prever valores alvo de novos dados. Você não precisa treinar novamente o estimador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)                          # Prevê classes dos dados de treinamento\n",
    "clf.predict([[4, 5, 6], [14, 15, 16]])  # prevê classes de novos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformadores e pré-processadores \n",
    "Os fluxos de trabalho de aprendizado de máquina geralmente são compostos de diferentes partes. Um pipeline típico consiste em uma etapa de pré-processamento que transforma ou introduz os dados e um preditor final que prevê valores de destino.\n",
    "\n",
    "No scikit-learn, pré-processadores e transformadores seguem a mesma API que os objetos estimadores (na verdade, todos eles herdam da mesma classe BaseEstimator). Os objetos do transformador não têm um método de previsão , mas sim um método de transformação que gera uma matriz de amostra recém-transformada X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [ 1., -1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = [[0, 15],\n",
    "     [1, -10]]\n",
    "# scale data according to computed scaling values\n",
    "StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Às vezes, você deseja aplicar diferentes transformações a diferentes recursos: o ColumnTransformer é projetado para esses casos de uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines: encadeamento de pré-processadores e estimadores\n",
    "\n",
    "Transformadores e estimadores (preditores) podem ser combinados em um único objeto unificador: um Pipeline. O pipeline oferece a mesma API que um estimador regular: ele pode ser ajustado e usado para previsão com *fit* e *predict*. Como veremos mais adiante, usar um pipeline também evitará vazamento de dados, ou seja, divulgar alguns dados de teste em seus dados de treinamento.\n",
    "\n",
    "No exemplo a seguir, carregamos o conjunto de dados ***Iris*** , dividimos em conjuntos de treinamento e de teste e calculamos a pontuação de precisão de um pipeline nos dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cria um objeto pipeline\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "#carrega uma base de dados. Neste exemplo, a base de dados \"Iris\"\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "#divide a base de dados em conjuntos de treinamento e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Ajusta o pipeline como um todo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "#podemos agora usá-lo como outro estimador qualquer\n",
    "accuracy_score(pipe.predict(X_test), y_test) #cálculo da pontuação de previsão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo\n",
    "\n",
    "Ajustar um modelo a alguns dados não implica que ele preveja bem dados não vistos. Isso precisa ser avaliado diretamente. Acabamos de ver o ***train_test_split*** auxiliar que divide um conjunto de dados em conjuntos de **treinamento** e de **teste**, mas scikit-learn fornece muitas outras ferramentas para avaliação de modelos, em particular para **validação cruzada** .\n",
    "\n",
    "Aqui mostramos brevemente como realizar um procedimento de validação cruzada de 5 vezes, usando o ***cross_validateauxiliar***. Observe que também é possível iterar manualmente nas dobras, usar diferentes estratégias de divisão de dados e usar funções de pontuação personalizadas. Consulte o [Guia do usuário do Scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) para obter mais detalhes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "rl = LinearRegression()\n",
    "\n",
    "resultado = cross_validate(rl, X, y)    # por padrão, faz uma validação cruzada de 5 vezes\n",
    "resultado['test_score']                 #a pontuação r_quadrado é alta porque a base de dados é simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pesquisas automáticas de parâmetros \n",
    "\n",
    "Todos os estimadores possuem parâmetros (muitas vezes chamados de **hiperparâmetros** na literatura) que podem ser ajustados. O poder de generalização de um estimador muitas vezes depende criticamente de alguns parâmetros. Por exemplo, a ***RandomForestRegressor*** tem um parâmetro ***n_estimators*** que determina o número de árvores na floresta e um parâmetro ***max_depth*** que determina a profundidade máxima de cada árvore. Muitas vezes, não está claro quais devem ser os valores exatos desses parâmetros, pois eles dependem dos dados disponíveis.\n",
    "\n",
    "O Scikit-learn fornece ferramentas para encontrar automaticamente as melhores combinações de parâmetros (via validação cruzada). No exemplo a seguir, pesquisamos aleatoriamente no espaço de parâmetros de uma floresta aleatória com um objeto ***RandomizedSearchCV***. Quando a pesquisa termina, o ***RandomizedSearchCV*** se comporta como um ***RandomForestRegressor*** que foi ajustado com o melhor conjunto de parâmetros. Leia mais no [Guia do usuário do Scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735363411343253"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "#definie o espaço de parâmetros que será pesquisado\n",
    "param_distributions = {'n_estimators': randint(1, 5),\n",
    "                       'max_depth': randint(5, 10)}\n",
    "\n",
    "#agora cria um objeto searchCV e o ajusta aos dados\n",
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions,\n",
    "                            random_state=0)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "search.best_params_\n",
    "\n",
    "#o objeto de pesquisa agora funciona como um estimador de floresta aleatória normal\n",
    "#com max_depth=9 and n_estimators=4\n",
    "search.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observação**<br>\n",
    "\n",
    "Na prática, você quase sempre deseja pesquisar em um pipeline , em vez de um único estimador. Uma das principais razões é que, se você aplicar uma etapa de pré-processamento a todo o conjunto de dados sem usar um pipeline e, em seguida, realizar qualquer tipo de validação cruzada, estará quebrando a suposição fundamental de independência entre dados de treinamento e teste. De fato, como você pré-processou os dados usando todo o conjunto de dados, algumas informações sobre os conjuntos de teste estão disponíveis para os conjuntos de treinamento. Isso levará a superestimar o poder de generalização do estimador (você pode ler mais neste [post do Kaggle](https://www.kaggle.com/alexisbcook/data-leakage) ).\n",
    "O uso de um pipeline para validação cruzada e pesquisa o manterá longe dessa armadilha comum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Próximos passos\n",
    "\n",
    "Cobrimos brevemente o ajuste e a previsão de estimadores, etapas de pré-processamento, pipelines, ferramentas de validação cruzada e pesquisas automáticas de hiperparâmetros. Este guia deve fornecer uma visão geral de alguns dos principais recursos da biblioteca, mas há muito mais no ***scikit-learn***!\n",
    "\n",
    "Consulte o [Guia do usuário do Scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)o para obter detalhes sobre todas as ferramentas que fornecemos. Você também pode encontrar uma lista completa da API pública na [API Reference](https://scikit-learn.org/stable/modules/classes.html#api-ref).\n",
    "\n",
    "Você também pode ver nossos inúmeros [exemplos](https://scikit-learn.org/stable/auto_examples/index.html#general-examples) que ilustram o uso de ***scikit-learn*** em muitos contextos diferentes.\n",
    "\n",
    "Os [tutoriais](https://scikit-learn.org/stable/tutorial/index.html#tutorial-menu) também contêm recursos de aprendizado adicionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "* https://scikit-learn.org/stable/getting_started.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec1eed7ba1d2779ad571cb3d56c9cc2145750a9a366aa19de7670ee4a571ff8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
